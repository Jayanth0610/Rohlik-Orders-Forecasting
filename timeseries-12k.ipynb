{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T00:54:05.283661Z",
     "iopub.status.busy": "2024-06-14T00:54:05.283293Z",
     "iopub.status.idle": "2024-06-14T00:54:06.208491Z",
     "shell.execute_reply": "2024-06-14T00:54:06.207414Z",
     "shell.execute_reply.started": "2024-06-14T00:54:05.283632Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/sjaya/AppData/Local/Microsoft/WindowsApps/python3.11.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "from colorama import Fore, Style\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import randint\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "from math import pi\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:01:51.920466Z",
     "iopub.status.busy": "2024-06-14T01:01:51.919533Z",
     "iopub.status.idle": "2024-06-14T01:01:51.951065Z",
     "shell.execute_reply": "2024-06-14T01:01:51.950112Z",
     "shell.execute_reply.started": "2024-06-14T01:01:51.920422Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv('/kaggle/input/rohlik-orders-forecasting-challenge/train.csv')\n",
    "df_ts = pd.read_csv('/kaggle/input/rohlik-orders-forecasting-challenge/test.csv')\n",
    "df_s = pd.read_csv('/kaggle/input/rohlik-orders-forecasting-challenge/solution_example.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:01:52.269448Z",
     "iopub.status.busy": "2024-06-14T01:01:52.269127Z",
     "iopub.status.idle": "2024-06-14T01:01:52.274439Z",
     "shell.execute_reply": "2024-06-14T01:01:52.273474Z",
     "shell.execute_reply.started": "2024-06-14T01:01:52.269424Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(df_ts.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:01:52.509322Z",
     "iopub.status.busy": "2024-06-14T01:01:52.508953Z",
     "iopub.status.idle": "2024-06-14T01:01:52.514314Z",
     "shell.execute_reply": "2024-06-14T01:01:52.513348Z",
     "shell.execute_reply.started": "2024-06-14T01:01:52.509295Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(df_tr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:01:52.580255Z",
     "iopub.status.busy": "2024-06-14T01:01:52.579860Z",
     "iopub.status.idle": "2024-06-14T01:01:52.587299Z",
     "shell.execute_reply": "2024-06-14T01:01:52.585947Z",
     "shell.execute_reply.started": "2024-06-14T01:01:52.580229Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['shutdown', 'mini_shutdown','blackout', 'mov_change', 'frankfurt_shutdown',\n",
    "       'precipitation', 'snow', 'user_activity_1', 'user_activity_2',]\n",
    "df_tr = df_tr.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:01:52.759797Z",
     "iopub.status.busy": "2024-06-14T01:01:52.759453Z",
     "iopub.status.idle": "2024-06-14T01:01:52.805684Z",
     "shell.execute_reply": "2024-06-14T01:01:52.804848Z",
     "shell.execute_reply.started": "2024-06-14T01:01:52.759768Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_tr.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:01:53.979952Z",
     "iopub.status.busy": "2024-06-14T01:01:53.979510Z",
     "iopub.status.idle": "2024-06-14T01:01:54.013841Z",
     "shell.execute_reply": "2024-06-14T01:01:54.012729Z",
     "shell.execute_reply.started": "2024-06-14T01:01:53.979876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_ts.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:01:54.745410Z",
     "iopub.status.busy": "2024-06-14T01:01:54.744666Z",
     "iopub.status.idle": "2024-06-14T01:01:54.764876Z",
     "shell.execute_reply": "2024-06-14T01:01:54.763817Z",
     "shell.execute_reply.started": "2024-06-14T01:01:54.745380Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(df_tr.info())\n",
    "print(\"--------------------------------------------------\")\n",
    "print(df_ts.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T22:30:30.028537Z",
     "iopub.status.busy": "2024-06-13T22:30:30.027774Z",
     "iopub.status.idle": "2024-06-13T22:30:30.035459Z",
     "shell.execute_reply": "2024-06-13T22:30:30.034492Z",
     "shell.execute_reply.started": "2024-06-13T22:30:30.028503Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_tr.drop(['id'], axis=1 , inplace=True)\n",
    "df_ts.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T22:30:33.184776Z",
     "iopub.status.busy": "2024-06-13T22:30:33.184044Z",
     "iopub.status.idle": "2024-06-13T22:30:33.616868Z",
     "shell.execute_reply": "2024-06-13T22:30:33.615753Z",
     "shell.execute_reply.started": "2024-06-13T22:30:33.184748Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# Load datasets\n",
    "train = df_tr.copy()\n",
    "test = df_ts.copy()\n",
    "\n",
    "# Feature Engineering\n",
    "def feature_engineering(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['week'] = df['date'].dt.isocalendar().week\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df['is_weekend'] = df['dayofweek'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    df['warehouse'] = le.fit_transform(df['warehouse'])\n",
    "    df['holiday_name'] = df['holiday_name'].fillna('No Holiday')\n",
    "    df['holiday_name'] = le.fit_transform(df['holiday_name'])\n",
    "    \n",
    "    df = df.drop(['date'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = feature_engineering(train)\n",
    "test = feature_engineering(test)\n",
    "\n",
    "# Split data\n",
    "X = train.drop(['orders'], axis=1)\n",
    "y = train['orders']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model 1: LightGBM\n",
    "lgb_model = LGBMRegressor()\n",
    "lgb_model.fit(X_train, y_train)\n",
    "lgb_val_preds = lgb_model.predict(X_val)\n",
    "lgb_mape = mean_absolute_percentage_error(y_val, lgb_val_preds)\n",
    "print(f'LightGBM MAPE: {lgb_mape}')\n",
    "\n",
    "# Model 2: XGBoost\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_val_preds = xgb_model.predict(X_val)\n",
    "xgb_mape = mean_absolute_percentage_error(y_val, xgb_val_preds)\n",
    "print(f'XGBoost MAPE: {xgb_mape}')\n",
    "\n",
    "# Model 3: Neural Network (LSTM)\n",
    "X_train_nn = np.expand_dims(X_train, axis=1)\n",
    "X_val_nn = np.expand_dims(X_val, axis=1)\n",
    "\n",
    "nn_model = Sequential()\n",
    "nn_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train_nn.shape[1], X_train_nn.shape[2])))\n",
    "nn_model.add(Dropout(0.2))\n",
    "nn_model.add(LSTM(units=50, return_sequences=False))\n",
    "nn_model.add(Dropout(0.2))\n",
    "nn_model.add(Dense(units=1))\n",
    "\n",
    "nn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "nn_model.fit(X_train_nn, y_train, epochs=50, batch_size=32, validation_data=(X_val_nn, y_val), callbacks=[early_stopping])\n",
    "\n",
    "nn_val_preds = nn_model.predict(X_val_nn).flatten()\n",
    "nn_mape = mean_absolute_percentage_error(y_val, nn_val_preds)\n",
    "print(f'LSTM Neural Network MAPE: {nn_mape}')\n",
    "\n",
    "# Ensemble Model\n",
    "ensemble_model = VotingRegressor(estimators=[\n",
    "    ('lgb', lgb_model),\n",
    "    ('xgb', xgb_model),\n",
    "    ('nn', keras.wrappers.scikit_learn.KerasRegressor(build_fn=lambda: nn_model, epochs=1, batch_size=32, verbose=0))\n",
    "])\n",
    "\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "ensemble_val_preds = ensemble_model.predict(X_val)\n",
    "ensemble_mape = mean_absolute_percentage_error(y_val, ensemble_val_preds)\n",
    "print(f'Ensemble Model MAPE: {ensemble_mape}')\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_preds = ensemble_model.predict(test)\n",
    "\n",
    "# Prepare submission\n",
    "submission = pd.DataFrame({'date': pd.read_csv('test.csv')['date'], 'orders': test_preds})\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:02:03.785689Z",
     "iopub.status.busy": "2024-06-14T01:02:03.785322Z",
     "iopub.status.idle": "2024-06-14T01:02:03.796193Z",
     "shell.execute_reply": "2024-06-14T01:02:03.794951Z",
     "shell.execute_reply.started": "2024-06-14T01:02:03.785662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_tr.drop(['holiday_name', 'holiday', 'shops_closed','winter_school_holidays', 'school_holidays'], axis=1 , inplace=True)\n",
    "df_ts.drop(['holiday_name', 'holiday', 'shops_closed','winter_school_holidays', 'school_holidays'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:02:04.309326Z",
     "iopub.status.busy": "2024-06-14T01:02:04.308957Z",
     "iopub.status.idle": "2024-06-14T01:02:04.326708Z",
     "shell.execute_reply": "2024-06-14T01:02:04.325766Z",
     "shell.execute_reply.started": "2024-06-14T01:02:04.309301Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(df_tr.info())\n",
    "print(\"--------------------------------------\")\n",
    "print(df_ts.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:02:05.260327Z",
     "iopub.status.busy": "2024-06-14T01:02:05.259931Z",
     "iopub.status.idle": "2024-06-14T01:02:05.273808Z",
     "shell.execute_reply": "2024-06-14T01:02:05.272748Z",
     "shell.execute_reply.started": "2024-06-14T01:02:05.260297Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to encode date cyclically with advanced features\n",
    "def advanced_cyclic_date_encoding(df, date_col):\n",
    "    df[date_col] = pd.to_datetime(df[date_col], format='%Y-%m-%d')\n",
    "    # Extract day, month, year, day of year, weekday, week of year, and quarter\n",
    "    df['day'] = df[date_col].dt.day\n",
    "    df['month'] = df[date_col].dt.month\n",
    "    df['year'] = df[date_col].dt.year\n",
    "    df['day_of_year'] = df[date_col].dt.dayofyear\n",
    "    df['weekday'] = df[date_col].dt.weekday\n",
    "    df['week_of_year'] = df[date_col].dt.isocalendar().week\n",
    "    df['quarter'] = df[date_col].dt.quarter\n",
    "    \n",
    "    # Normalize these features\n",
    "    df['day_norm'] = df['day'] / 31.0\n",
    "    df['month_norm'] = df['month'] / 12.0\n",
    "    df['day_of_year_norm'] = df['day_of_year'] / 366.0\n",
    "    df['weekday_norm'] = df['weekday'] / 7.0\n",
    "    df['week_of_year_norm'] = df['week_of_year'] / 53.0\n",
    "    df['quarter_norm'] = df['quarter'] / 4.0\n",
    "    \n",
    "    # Apply sine and cosine transformations\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day_norm'])\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day_norm'])\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month_norm'])\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month_norm'])\n",
    "    df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year_norm'])\n",
    "    df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year_norm'])\n",
    "    df['weekday_sin'] = np.sin(2 * np.pi * df['weekday_norm'])\n",
    "    df['weekday_cos'] = np.cos(2 * np.pi * df['weekday_norm'])\n",
    "    df['week_of_year_sin'] = np.sin(2 * np.pi * df['week_of_year_norm'])\n",
    "    df['week_of_year_cos'] = np.cos(2 * np.pi * df['week_of_year_norm'])\n",
    "    df['quarter_sin'] = np.sin(2 * np.pi * df['quarter_norm'])\n",
    "    df['quarter_cos'] = np.cos(2 * np.pi * df['quarter_norm'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:02:16.295123Z",
     "iopub.status.busy": "2024-06-14T01:02:16.294282Z",
     "iopub.status.idle": "2024-06-14T01:02:16.371126Z",
     "shell.execute_reply": "2024-06-14T01:02:16.370245Z",
     "shell.execute_reply.started": "2024-06-14T01:02:16.295075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_tr = advanced_cyclic_date_encoding(df_tr, 'date')\n",
    "df_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:02:18.470212Z",
     "iopub.status.busy": "2024-06-14T01:02:18.469422Z",
     "iopub.status.idle": "2024-06-14T01:02:18.478053Z",
     "shell.execute_reply": "2024-06-14T01:02:18.477194Z",
     "shell.execute_reply.started": "2024-06-14T01:02:18.470179Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_tr.drop(['id', 'date'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:02:19.434754Z",
     "iopub.status.busy": "2024-06-14T01:02:19.434361Z",
     "iopub.status.idle": "2024-06-14T01:02:19.442791Z",
     "shell.execute_reply": "2024-06-14T01:02:19.441934Z",
     "shell.execute_reply.started": "2024-06-14T01:02:19.434723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "le_warehouse = LabelEncoder()\n",
    "df_tr['warehouse'] = le_warehouse.fit_transform(df_tr['warehouse'])\n",
    "df_ts['warehouse'] = le_warehouse.transform(df_ts['warehouse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:02:20.849945Z",
     "iopub.status.busy": "2024-06-14T01:02:20.849230Z",
     "iopub.status.idle": "2024-06-14T01:02:23.615551Z",
     "shell.execute_reply": "2024-06-14T01:02:23.614637Z",
     "shell.execute_reply.started": "2024-06-14T01:02:20.849906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Calculate Correlation Matrix\n",
    "corr_matrix = df_tr.corr()\n",
    "\n",
    "# Plot using Seaborn Heatmap\n",
    "plt.figure(figsize=(18, 12))  # Adjust figure size as needed\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:02:25.085309Z",
     "iopub.status.busy": "2024-06-14T01:02:25.084955Z",
     "iopub.status.idle": "2024-06-14T01:02:25.126075Z",
     "shell.execute_reply": "2024-06-14T01:02:25.125018Z",
     "shell.execute_reply.started": "2024-06-14T01:02:25.085283Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calculate Correlation Matrix\n",
    "corr_matrix = df_tr.corr()\n",
    "\n",
    "# Threshold for High Correlation\n",
    "threshold = 0.75\n",
    "\n",
    "# Filter Features to Drop (Highly Correlated with Others)\n",
    "features_to_drop = set()\n",
    "for col in corr_matrix.columns:\n",
    "    for other_col in corr_matrix.columns:\n",
    "        if col != other_col:  # Avoid self-correlation\n",
    "            corr = abs(corr_matrix.loc[col, other_col])\n",
    "            if corr >= threshold:\n",
    "                features_to_drop.add(max(col, other_col))  # Drop the higher-indexed feature\n",
    "\n",
    "# Drop Featuresa\n",
    "df_tr = df_tr.drop(features_to_drop, axis=1)\n",
    "df_tr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:02:31.415113Z",
     "iopub.status.busy": "2024-06-14T01:02:31.414731Z",
     "iopub.status.idle": "2024-06-14T01:02:31.422009Z",
     "shell.execute_reply": "2024-06-14T01:02:31.420952Z",
     "shell.execute_reply.started": "2024-06-14T01:02:31.415088Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = df_tr.drop('orders', axis=1)\n",
    "y = df_tr['orders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:02:36.904498Z",
     "iopub.status.busy": "2024-06-14T01:02:36.904143Z",
     "iopub.status.idle": "2024-06-14T01:02:36.916147Z",
     "shell.execute_reply": "2024-06-14T01:02:36.915015Z",
     "shell.execute_reply.started": "2024-06-14T01:02:36.904471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:02:38.349727Z",
     "iopub.status.busy": "2024-06-14T01:02:38.349354Z",
     "iopub.status.idle": "2024-06-14T01:02:38.401801Z",
     "shell.execute_reply": "2024-06-14T01:02:38.400923Z",
     "shell.execute_reply.started": "2024-06-14T01:02:38.349696Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_ts = advanced_cyclic_date_encoding(df_ts, 'date')\n",
    "df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:02:39.580066Z",
     "iopub.status.busy": "2024-06-14T01:02:39.579348Z",
     "iopub.status.idle": "2024-06-14T01:02:39.587149Z",
     "shell.execute_reply": "2024-06-14T01:02:39.586115Z",
     "shell.execute_reply.started": "2024-06-14T01:02:39.580031Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_ts.drop(['id', 'date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:02:51.024548Z",
     "iopub.status.busy": "2024-06-14T01:02:51.024189Z",
     "iopub.status.idle": "2024-06-14T01:02:51.031566Z",
     "shell.execute_reply": "2024-06-14T01:02:51.030524Z",
     "shell.execute_reply.started": "2024-06-14T01:02:51.024521Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test=df_ts[['warehouse', 'day', 'year', 'day_of_year', 'weekday',\n",
    "       'day_cos', 'day_of_year_cos', 'weekday_sin', 'weekday_cos']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-06-14T01:03:37.305359Z",
     "iopub.status.busy": "2024-06-14T01:03:37.304703Z",
     "iopub.status.idle": "2024-06-14T01:03:52.720706Z",
     "shell.execute_reply": "2024-06-14T01:03:52.719607Z",
     "shell.execute_reply.started": "2024-06-14T01:03:37.305326Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the models\n",
    "models = [\n",
    "    ('rf', RandomForestRegressor(random_state=42)),\n",
    "    ('xgb', XGBRegressor(objective='reg:squarederror', random_state=42)),\n",
    "    ('lgbm', LGBMRegressor(objective='regression', random_state=42)),\n",
    "    ('catboost', CatBoostRegressor(iterations=200,random_state=42)),\n",
    "]\n",
    "\n",
    "# Define the KFold object\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize the MAPE scores\n",
    "mape_scores = np.zeros((len(models),))\n",
    "\n",
    "# Loop through each model\n",
    "for i, (name, model) in enumerate(models):\n",
    "    mape_scores_model = []\n",
    "    # Loop through each fold\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on the validation set\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        # Calculate MAPE\n",
    "        mape = mean_absolute_percentage_error(y_val, y_pred)\n",
    "        mape_scores_model.append(mape)\n",
    "    \n",
    "    # Calculate the average MAPE score for this model\n",
    "    mape_scores[i] = np.mean(mape_scores_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:03:52.722936Z",
     "iopub.status.busy": "2024-06-14T01:03:52.722589Z",
     "iopub.status.idle": "2024-06-14T01:03:52.728554Z",
     "shell.execute_reply": "2024-06-14T01:03:52.727488Z",
     "shell.execute_reply.started": "2024-06-14T01:03:52.722877Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Print the MAPE scores for each model\n",
    "for i, (name, model) in enumerate(models):\n",
    "    print(f\"Model: {name}, MAPE: {mape_scores[i]:.5f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-06-14T01:03:52.730307Z",
     "iopub.status.busy": "2024-06-14T01:03:52.729914Z",
     "iopub.status.idle": "2024-06-14T01:04:08.276248Z",
     "shell.execute_reply": "2024-06-14T01:04:08.274945Z",
     "shell.execute_reply.started": "2024-06-14T01:03:52.730270Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create the ensemble model with soft voting\n",
    "weights = 1 / mape_scores\n",
    "ensemble = VotingRegressor(estimators=models, weights=weights)\n",
    "\n",
    "# Evaluate the ensemble model with 5-fold cross-validation\n",
    "mape_scores_ensemble = []\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    ensemble.fit(X_train, y_train)\n",
    "    y_pred = ensemble.predict(X_val)\n",
    "    mape = mean_absolute_percentage_error(y_val, y_pred)\n",
    "    mape_scores_ensemble.append(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:04:08.279231Z",
     "iopub.status.busy": "2024-06-14T01:04:08.278322Z",
     "iopub.status.idle": "2024-06-14T01:04:08.284668Z",
     "shell.execute_reply": "2024-06-14T01:04:08.283601Z",
     "shell.execute_reply.started": "2024-06-14T01:04:08.279185Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mape_ensemble = np.mean(mape_scores_ensemble)\n",
    "print(f\"Ensemble MAPE: {mape_ensemble:.5f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-06-14T01:04:08.288370Z",
     "iopub.status.busy": "2024-06-14T01:04:08.288051Z",
     "iopub.status.idle": "2024-06-14T01:04:11.896477Z",
     "shell.execute_reply": "2024-06-14T01:04:11.895555Z",
     "shell.execute_reply.started": "2024-06-14T01:04:08.288335Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Determine the best model\n",
    "best_model_index = np.argmin(mape_scores)\n",
    "best_model = models[best_model_index][1]\n",
    "best_mape = mape_scores[best_model_index]\n",
    "\n",
    "if mape_ensemble < best_mape:\n",
    "    print(\"Ensemble model performs better.\")\n",
    "    final_model = ensemble\n",
    "else:\n",
    "    print(f\"{models[best_model_index][0]} model performs better.\")\n",
    "    final_model = best_model\n",
    "\n",
    "# Generate predictions on the test set using the best model\n",
    "final_model.fit(X, y)\n",
    "y_pred_test = final_model.predict(df_test)\n",
    "\n",
    "# You can now use y_pred_test for further analysis or to create a submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:04:11.898180Z",
     "iopub.status.busy": "2024-06-14T01:04:11.897596Z",
     "iopub.status.idle": "2024-06-14T01:04:11.909450Z",
     "shell.execute_reply": "2024-06-14T01:04:11.908279Z",
     "shell.execute_reply.started": "2024-06-14T01:04:11.898146Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:04:21.539702Z",
     "iopub.status.busy": "2024-06-14T01:04:21.539344Z",
     "iopub.status.idle": "2024-06-14T01:04:21.552240Z",
     "shell.execute_reply": "2024-06-14T01:04:21.551354Z",
     "shell.execute_reply.started": "2024-06-14T01:04:21.539674Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_s['orders']=y_pred_test\n",
    "df_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T01:04:32.154985Z",
     "iopub.status.busy": "2024-06-14T01:04:32.154343Z",
     "iopub.status.idle": "2024-06-14T01:04:32.162566Z",
     "shell.execute_reply": "2024-06-14T01:04:32.161623Z",
     "shell.execute_reply.started": "2024-06-14T01:04:32.154952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_s = df_s.set_index('id')\n",
    "df_s.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "_______\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T21:31:25.885826Z",
     "iopub.status.busy": "2024-06-13T21:31:25.885497Z",
     "iopub.status.idle": "2024-06-13T21:31:25.899160Z",
     "shell.execute_reply": "2024-06-13T21:31:25.898208Z",
     "shell.execute_reply.started": "2024-06-13T21:31:25.885804Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T21:31:32.641270Z",
     "iopub.status.busy": "2024-06-13T21:31:32.640641Z",
     "iopub.status.idle": "2024-06-13T21:31:32.652598Z",
     "shell.execute_reply": "2024-06-13T21:31:32.651700Z",
     "shell.execute_reply.started": "2024-06-13T21:31:32.641242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T21:31:56.976627Z",
     "iopub.status.busy": "2024-06-13T21:31:56.975895Z",
     "iopub.status.idle": "2024-06-13T21:31:56.982876Z",
     "shell.execute_reply": "2024-06-13T21:31:56.981903Z",
     "shell.execute_reply.started": "2024-06-13T21:31:56.976594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "full=pd.concat([df_tr, df_ts], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T21:32:08.586377Z",
     "iopub.status.busy": "2024-06-13T21:32:08.585960Z",
     "iopub.status.idle": "2024-06-13T21:32:08.599007Z",
     "shell.execute_reply": "2024-06-13T21:32:08.598028Z",
     "shell.execute_reply.started": "2024-06-13T21:32:08.586348Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T21:34:08.311736Z",
     "iopub.status.busy": "2024-06-13T21:34:08.310933Z",
     "iopub.status.idle": "2024-06-13T21:34:08.316540Z",
     "shell.execute_reply": "2024-06-13T21:34:08.315515Z",
     "shell.execute_reply.started": "2024-06-13T21:34:08.311707Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "full.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T21:34:12.627060Z",
     "iopub.status.busy": "2024-06-13T21:34:12.626382Z",
     "iopub.status.idle": "2024-06-13T21:34:12.674988Z",
     "shell.execute_reply": "2024-06-13T21:34:12.674057Z",
     "shell.execute_reply.started": "2024-06-13T21:34:12.627015Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = advanced_cyclic_encoding(full, 'date', fourier_components=7737)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T21:38:06.137447Z",
     "iopub.status.busy": "2024-06-13T21:38:06.137070Z",
     "iopub.status.idle": "2024-06-13T21:38:06.144493Z",
     "shell.execute_reply": "2024-06-13T21:38:06.143423Z",
     "shell.execute_reply.started": "2024-06-13T21:38:06.137399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_last_397(df):\n",
    "    test_df = df.iloc[-397:]\n",
    "    train_df = df.iloc[:-397]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = split_last_397(df.copy())  # Copy to avoid modifying original df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T21:39:49.171550Z",
     "iopub.status.busy": "2024-06-13T21:39:49.170825Z",
     "iopub.status.idle": "2024-06-13T21:39:49.177498Z",
     "shell.execute_reply": "2024-06-13T21:39:49.176500Z",
     "shell.execute_reply.started": "2024-06-13T21:39:49.171520Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T21:40:01.306532Z",
     "iopub.status.busy": "2024-06-13T21:40:01.306142Z",
     "iopub.status.idle": "2024-06-13T21:40:01.312599Z",
     "shell.execute_reply": "2024-06-13T21:40:01.311711Z",
     "shell.execute_reply.started": "2024-06-13T21:40:01.306502Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T21:41:32.307245Z",
     "iopub.status.busy": "2024-06-13T21:41:32.306851Z",
     "iopub.status.idle": "2024-06-13T21:41:32.314835Z",
     "shell.execute_reply": "2024-06-13T21:41:32.313926Z",
     "shell.execute_reply.started": "2024-06-13T21:41:32.307215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df.drop(['index','id'], axis=1, inplace=True)\n",
    "test_df.drop(['index','id', 'orders'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T21:42:26.216496Z",
     "iopub.status.busy": "2024-06-13T21:42:26.216108Z",
     "iopub.status.idle": "2024-06-13T21:42:26.224257Z",
     "shell.execute_reply": "2024-06-13T21:42:26.223249Z",
     "shell.execute_reply.started": "2024-06-13T21:42:26.216469Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "le_warehouse = LabelEncoder()\n",
    "train_df['warehouse'] = le_warehouse.fit_transform(train_df['warehouse'])\n",
    "test_df['warehouse'] = le_warehouse.transform(test_df['warehouse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T21:43:42.662742Z",
     "iopub.status.busy": "2024-06-13T21:43:42.661903Z",
     "iopub.status.idle": "2024-06-13T21:43:42.668720Z",
     "shell.execute_reply": "2024-06-13T21:43:42.667834Z",
     "shell.execute_reply.started": "2024-06-13T21:43:42.662710Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "min_val = train_df['fourier_year'].min()\n",
    "max_val = train_df['fourier_year'].max()\n",
    "\n",
    "train_df['fourier_year'] = (train_df['fourier_year'] - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T21:43:52.001858Z",
     "iopub.status.busy": "2024-06-13T21:43:52.001494Z",
     "iopub.status.idle": "2024-06-13T21:43:52.010502Z",
     "shell.execute_reply": "2024-06-13T21:43:52.009485Z",
     "shell.execute_reply.started": "2024-06-13T21:43:52.001830Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "min_val = test_df['fourier_year'].min()\n",
    "max_val = test_df['fourier_year'].max()\n",
    "\n",
    "test_df['fourier_year'] = (test_df['fourier_year'] - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T21:44:51.476956Z",
     "iopub.status.busy": "2024-06-13T21:44:51.476594Z",
     "iopub.status.idle": "2024-06-13T21:44:51.483020Z",
     "shell.execute_reply": "2024-06-13T21:44:51.482193Z",
     "shell.execute_reply.started": "2024-06-13T21:44:51.476926Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = train_df.drop('orders', axis=1)\n",
    "y = train_df['orders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-06-13T21:45:59.192107Z",
     "iopub.status.busy": "2024-06-13T21:45:59.191359Z",
     "iopub.status.idle": "2024-06-13T21:46:11.709682Z",
     "shell.execute_reply": "2024-06-13T21:46:11.708722Z",
     "shell.execute_reply.started": "2024-06-13T21:45:59.192079Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = [\n",
    "    ('rf', RandomForestRegressor(random_state=42)),\n",
    "    ('xgb', XGBRegressor(objective='reg:squarederror', random_state=42)),\n",
    "    ('lgbm', LGBMRegressor(objective='regression', random_state=42)),\n",
    "    ('catboost', CatBoostRegressor(iterations=200,random_state=42)),\n",
    "]\n",
    "\n",
    "# Define the KFold object\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize the MAPE scores\n",
    "mape_scores = np.zeros((len(models),))\n",
    "\n",
    "# Loop through each model\n",
    "for i, (name, model) in enumerate(models):\n",
    "    mape_scores_model = []\n",
    "    # Loop through each fold\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on the validation set\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        # Calculate MAPE\n",
    "        mape = mean_absolute_percentage_error(y_val, y_pred)\n",
    "        mape_scores_model.append(mape)\n",
    "    \n",
    "    # Calculate the average MAPE score for this model\n",
    "    mape_scores[i] = np.mean(mape_scores_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T21:46:11.711524Z",
     "iopub.status.busy": "2024-06-13T21:46:11.711208Z",
     "iopub.status.idle": "2024-06-13T21:46:11.716393Z",
     "shell.execute_reply": "2024-06-13T21:46:11.715502Z",
     "shell.execute_reply.started": "2024-06-13T21:46:11.711499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Print the MAPE scores for each model\n",
    "for i, (name, model) in enumerate(models):\n",
    "    print(f\"Model: {name}, MAPE: {mape_scores[i]:.5f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-06-13T21:46:11.718367Z",
     "iopub.status.busy": "2024-06-13T21:46:11.717993Z",
     "iopub.status.idle": "2024-06-13T21:46:24.106834Z",
     "shell.execute_reply": "2024-06-13T21:46:24.106059Z",
     "shell.execute_reply.started": "2024-06-13T21:46:11.718328Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create the ensemble model with soft voting\n",
    "weights = 1 / mape_scores\n",
    "ensemble = VotingRegressor(estimators=models, weights=weights)\n",
    "\n",
    "# Evaluate the ensemble model with 5-fold cross-validation\n",
    "mape_scores_ensemble = []\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    ensemble.fit(X_train, y_train)\n",
    "    y_pred = ensemble.predict(X_val)\n",
    "    mape = mean_absolute_percentage_error(y_val, y_pred)\n",
    "    mape_scores_ensemble.append(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T21:46:24.108807Z",
     "iopub.status.busy": "2024-06-13T21:46:24.108518Z",
     "iopub.status.idle": "2024-06-13T21:46:24.114156Z",
     "shell.execute_reply": "2024-06-13T21:46:24.113143Z",
     "shell.execute_reply.started": "2024-06-13T21:46:24.108781Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mape_ensemble = np.mean(mape_scores_ensemble)\n",
    "print(f\"Ensemble MAPE: {mape_ensemble:.5f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-06-13T21:46:24.115506Z",
     "iopub.status.busy": "2024-06-13T21:46:24.115210Z",
     "iopub.status.idle": "2024-06-13T21:46:27.127656Z",
     "shell.execute_reply": "2024-06-13T21:46:27.126826Z",
     "shell.execute_reply.started": "2024-06-13T21:46:24.115483Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Determine the best model\n",
    "best_model_index = np.argmin(mape_scores)\n",
    "best_model = models[best_model_index][1]\n",
    "best_mape = mape_scores[best_model_index]\n",
    "\n",
    "if mape_ensemble < best_mape:\n",
    "    print(\"Ensemble model performs better.\")\n",
    "    final_model = ensemble\n",
    "else:\n",
    "    print(f\"{models[best_model_index][0]} model performs better.\")\n",
    "    final_model = best_model\n",
    "\n",
    "# Generate predictions on the test set using the best model\n",
    "final_model.fit(X, y)\n",
    "y_pred_test = final_model.predict(test_df)\n",
    "\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T22:56:06.644414Z",
     "iopub.status.busy": "2024-06-13T22:56:06.644022Z",
     "iopub.status.idle": "2024-06-13T22:56:06.659768Z",
     "shell.execute_reply": "2024-06-13T22:56:06.658847Z",
     "shell.execute_reply.started": "2024-06-13T22:56:06.644385Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "import statsmodels.api as sm\n",
    "from scipy import fftpack\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "def fuck_df(df):\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "    # ---------- Basic Date Components ----------\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day_of_month'] = df['date'].dt.day\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)  \n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "\n",
    "\n",
    "    # ---------- Cyclical Encoding ----------\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365.25)\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365.25)\n",
    "    df['week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "\n",
    "    # ---------- Trend and Seasonality Decomposition ----------\n",
    "    stl = STL(df['orders'], period=365)  # Assuming yearly seasonality\n",
    "    res = stl.fit()\n",
    "    df['trend'] = res.trend\n",
    "    df['seasonality'] = res.seasonal\n",
    "\n",
    "    # ---------- Autocorrelation Features ----------\n",
    "    lags = [7, 14, 28, 56]  # Example lags to consider\n",
    "    for lag in lags:\n",
    "        df[f'autocorr_{lag}'] = acf(df['orders'], nlags=lag)[-1]\n",
    "        df[f'pacf_{lag}'] = pacf(df['orders'], nlags=lag)[-1]\n",
    "\n",
    "\n",
    "    # ---------- Time-Varying Features (Exponential Smoothing) ----------\n",
    "    # Simple Exponential Smoothing\n",
    "    alpha = 0.2  # You can optimize this value\n",
    "    df['ses'] = df['orders'].ewm(alpha=alpha, adjust=False).mean()\n",
    "\n",
    "    # Double Exponential Smoothing\n",
    "    df['des_level'] = df['orders'].ewm(alpha=alpha, adjust=False).mean()\n",
    "    df['des_trend'] = (df['des_level'] - df['des_level'].shift(1)).ewm(alpha=alpha, adjust=False).mean()\n",
    "\n",
    "    # ---------- Frequency Domain Features (FFT) ----------\n",
    "    fft = fftpack.fft(df['orders'].values)  # Convert Series to numpy array.\n",
    "    df['fft_amplitude'] = np.abs(fft)\n",
    "    df['fft_phase'] = np.angle(fft)\n",
    "    \n",
    "    # ---------- Interaction Terms (Example) ----------\n",
    "    df['month_is_weekend'] = df['month'] * df['is_weekend']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T22:56:07.602573Z",
     "iopub.status.busy": "2024-06-13T22:56:07.602238Z",
     "iopub.status.idle": "2024-06-13T22:56:10.241113Z",
     "shell.execute_reply": "2024-06-13T22:56:10.239744Z",
     "shell.execute_reply.started": "2024-06-13T22:56:07.602547Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_tr=fuck_df(df_tr.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T22:56:17.019460Z",
     "iopub.status.busy": "2024-06-13T22:56:17.018457Z",
     "iopub.status.idle": "2024-06-13T22:56:17.056391Z",
     "shell.execute_reply": "2024-06-13T22:56:17.055370Z",
     "shell.execute_reply.started": "2024-06-13T22:56:17.019404Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variable and features\n",
    "y = df['orders'] \n",
    "X = df.drop('orders', axis=1)\n",
    "\n",
    "# Time Series Cross-Validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "mape_scores = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Train XGBoost model\n",
    "    model = XGBRegressor()  \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate MAPE\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    mape_scores.append(mape)\n",
    "\n",
    "# Average MAPE across folds\n",
    "avg_mape = sum(mape_scores) / len(mape_scores)\n",
    "print(\"Average MAPE:\", avg_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T22:59:21.578775Z",
     "iopub.status.busy": "2024-06-13T22:59:21.577964Z",
     "iopub.status.idle": "2024-06-13T22:59:21.585712Z",
     "shell.execute_reply": "2024-06-13T22:59:21.584627Z",
     "shell.execute_reply.started": "2024-06-13T22:59:21.578743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_tr['holiday_name'].fillna('noholiday', inplace=True)\n",
    "df_ts['holiday_name'].fillna('noholiday', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T22:59:23.518260Z",
     "iopub.status.busy": "2024-06-13T22:59:23.517479Z",
     "iopub.status.idle": "2024-06-13T22:59:23.525024Z",
     "shell.execute_reply": "2024-06-13T22:59:23.524076Z",
     "shell.execute_reply.started": "2024-06-13T22:59:23.518228Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_tr = df_tr.drop(['id'], axis=1)\n",
    "df_ts = df_ts.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T22:59:24.442654Z",
     "iopub.status.busy": "2024-06-13T22:59:24.442348Z",
     "iopub.status.idle": "2024-06-13T22:59:24.451696Z",
     "shell.execute_reply": "2024-06-13T22:59:24.450848Z",
     "shell.execute_reply.started": "2024-06-13T22:59:24.442629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "object_cols = df_tr.select_dtypes(include='object').columns\n",
    "\n",
    "# Print unique values for each object column\n",
    "for col in object_cols:\n",
    "  unique_values = df_tr[col].unique()\n",
    "  print(f\"Unique values in column '{col}': {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T22:59:25.157528Z",
     "iopub.status.busy": "2024-06-13T22:59:25.157205Z",
     "iopub.status.idle": "2024-06-13T22:59:25.164776Z",
     "shell.execute_reply": "2024-06-13T22:59:25.163878Z",
     "shell.execute_reply.started": "2024-06-13T22:59:25.157502Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "object_cols = df_ts.select_dtypes(include='object').columns\n",
    "\n",
    "# Print unique values for each object column\n",
    "for col in object_cols:\n",
    "  unique_values = df_ts[col].unique()\n",
    "  print(f\"Unique values in column '{col}': {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T22:59:26.812689Z",
     "iopub.status.busy": "2024-06-13T22:59:26.812341Z",
     "iopub.status.idle": "2024-06-13T22:59:26.824249Z",
     "shell.execute_reply": "2024-06-13T22:59:26.823230Z",
     "shell.execute_reply.started": "2024-06-13T22:59:26.812662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "le_warehouse = LabelEncoder()\n",
    "le_holiday_name = LabelEncoder()\n",
    "\n",
    "# Fit and transform training data\n",
    "\n",
    "df_tr['warehouse'] = le_warehouse.fit_transform(df_tr['warehouse'])\n",
    "df_tr['holiday_name'] = le_holiday_name.fit_transform(df_tr['holiday_name'])\n",
    "\n",
    "# Transform test data using the fitted encoders from training\n",
    "df_ts['warehouse'] = le_warehouse.transform(df_ts['warehouse'])\n",
    "df_ts['holiday_name'] = le_holiday_name.transform(df_ts['holiday_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T22:59:30.138904Z",
     "iopub.status.busy": "2024-06-13T22:59:30.137993Z",
     "iopub.status.idle": "2024-06-13T22:59:30.172866Z",
     "shell.execute_reply": "2024-06-13T22:59:30.172163Z",
     "shell.execute_reply.started": "2024-06-13T22:59:30.138870Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def cyclic_encode_date(df, date_col):\n",
    "\n",
    "  # Extract year, month, day (assuming the format YYYY-MM-DD)\n",
    "    df['year'] = pd.to_datetime(df[date_col]).dt.year - 2020\n",
    "    df['month'] = pd.to_datetime(df[date_col]).dt.month / 12  # Normalize to 0-1 range\n",
    "    df['day'] = pd.to_datetime(df[date_col]).dt.day / 31  # Normalize to 0-1 range (assuming 31 days)\n",
    "\n",
    "      # Apply sine and cosine transformations\n",
    "    df['year_sin'] = df['year'] * np.sin(2 * pi * df['year'])\n",
    "    df['year_cos'] = df['year'] * np.cos(2 * pi * df['year'])\n",
    "    df['month_sin'] = df['month'] * np.sin(2 * pi * df['month'])\n",
    "    df['month_cos'] = df['month'] * np.cos(2 * pi * df['month'])\n",
    "    df['day_sin'] = df['day'] * np.sin(2 * pi * df['day'])\n",
    "    df['day_cos'] = df['day'] * np.cos(2 * pi * df['day'])\n",
    "    return df\n",
    "\n",
    "# Apply cyclic encoding to your DataFrame\n",
    "df_tr = cyclic_encode_date(df_tr,'date')\n",
    "df_ts = cyclic_encode_date(df_ts,'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T22:59:34.098484Z",
     "iopub.status.busy": "2024-06-13T22:59:34.097638Z",
     "iopub.status.idle": "2024-06-13T22:59:34.105943Z",
     "shell.execute_reply": "2024-06-13T22:59:34.104990Z",
     "shell.execute_reply.started": "2024-06-13T22:59:34.098451Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_tr.drop('date', axis=1,inplace=True)\n",
    "df_ts.drop('date', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T22:34:41.773226Z",
     "iopub.status.busy": "2024-06-13T22:34:41.772420Z",
     "iopub.status.idle": "2024-06-13T22:34:41.800263Z",
     "shell.execute_reply": "2024-06-13T22:34:41.799268Z",
     "shell.execute_reply.started": "2024-06-13T22:34:41.773194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:00:08.863846Z",
     "iopub.status.busy": "2024-06-13T23:00:08.863105Z",
     "iopub.status.idle": "2024-06-13T23:00:09.866310Z",
     "shell.execute_reply": "2024-06-13T23:00:09.865429Z",
     "shell.execute_reply.started": "2024-06-13T23:00:08.863810Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Calculate Correlation Matrix\n",
    "corr_matrix = df_tr.corr()\n",
    "\n",
    "# Plot using Seaborn Heatmap\n",
    "plt.figure(figsize=(18, 12))  # Adjust figure size as needed\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:05:42.547869Z",
     "iopub.status.busy": "2024-06-13T23:05:42.547097Z",
     "iopub.status.idle": "2024-06-13T23:05:42.569183Z",
     "shell.execute_reply": "2024-06-13T23:05:42.568311Z",
     "shell.execute_reply.started": "2024-06-13T23:05:42.547834Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calculate Correlation Matrix\n",
    "corr_matrix = df_tr.corr()\n",
    "\n",
    "# Threshold for High Correlation\n",
    "threshold = 0.75\n",
    "\n",
    "# Filter Features to Drop (Highly Correlated with Others)\n",
    "features_to_drop = set()\n",
    "for col in corr_matrix.columns:\n",
    "    for other_col in corr_matrix.columns:\n",
    "        if col != other_col:  # Avoid self-correlation\n",
    "            corr = abs(corr_matrix.loc[col, other_col])\n",
    "            if corr >= threshold:\n",
    "                features_to_drop.add(max(col, other_col))  # Drop the higher-indexed feature\n",
    "\n",
    "# Drop Featuresa\n",
    "df_tr = df_tr.drop(features_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:05:52.921315Z",
     "iopub.status.busy": "2024-06-13T23:05:52.920927Z",
     "iopub.status.idle": "2024-06-13T23:05:52.927666Z",
     "shell.execute_reply": "2024-06-13T23:05:52.926772Z",
     "shell.execute_reply.started": "2024-06-13T23:05:52.921266Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_tr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:02:43.548721Z",
     "iopub.status.busy": "2024-06-13T23:02:43.547982Z",
     "iopub.status.idle": "2024-06-13T23:02:44.337374Z",
     "shell.execute_reply": "2024-06-13T23:02:44.336483Z",
     "shell.execute_reply.started": "2024-06-13T23:02:43.548689Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Calculate Correlation Matrix\n",
    "corr_matrix = df_ts.corr()\n",
    "\n",
    "# Plot using Seaborn Heatmap\n",
    "plt.figure(figsize=(18, 12))  # Adjust figure size as needed\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:06:55.036560Z",
     "iopub.status.busy": "2024-06-13T23:06:55.035899Z",
     "iopub.status.idle": "2024-06-13T23:06:55.043319Z",
     "shell.execute_reply": "2024-06-13T23:06:55.042356Z",
     "shell.execute_reply.started": "2024-06-13T23:06:55.036528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_ts=df_ts[['warehouse', 'holiday', 'shops_closed',\n",
    "       'winter_school_holidays', 'school_holidays', 'year', 'month', 'day',\n",
    "       'month_sin', 'month_cos', 'day_cos']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:07:04.151478Z",
     "iopub.status.busy": "2024-06-13T23:07:04.150611Z",
     "iopub.status.idle": "2024-06-13T23:07:04.157213Z",
     "shell.execute_reply": "2024-06-13T23:07:04.156269Z",
     "shell.execute_reply.started": "2024-06-13T23:07:04.151446Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_ts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:07:35.777006Z",
     "iopub.status.busy": "2024-06-13T23:07:35.775981Z",
     "iopub.status.idle": "2024-06-13T23:07:35.792856Z",
     "shell.execute_reply": "2024-06-13T23:07:35.791771Z",
     "shell.execute_reply.started": "2024-06-13T23:07:35.776971Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(df_tr.info())\n",
    "print(df_ts.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:07:42.966387Z",
     "iopub.status.busy": "2024-06-13T23:07:42.965450Z",
     "iopub.status.idle": "2024-06-13T23:07:42.972190Z",
     "shell.execute_reply": "2024-06-13T23:07:42.971331Z",
     "shell.execute_reply.started": "2024-06-13T23:07:42.966354Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = df_tr.drop('orders', axis=1)\n",
    "y = df_tr['orders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:07:45.886028Z",
     "iopub.status.busy": "2024-06-13T23:07:45.885275Z",
     "iopub.status.idle": "2024-06-13T23:07:45.901851Z",
     "shell.execute_reply": "2024-06-13T23:07:45.901036Z",
     "shell.execute_reply.started": "2024-06-13T23:07:45.885998Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=['float64', 'int64', 'int32']).columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X[numeric_cols])  # Fit the scaler to your training data (important!)\n",
    "\n",
    "# Transform the data\n",
    "X_scaled = X.copy()\n",
    "X_scaled[numeric_cols] = scaler.transform(X[numeric_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:07:50.015849Z",
     "iopub.status.busy": "2024-06-13T23:07:50.015482Z",
     "iopub.status.idle": "2024-06-13T23:07:50.123017Z",
     "shell.execute_reply": "2024-06-13T23:07:50.122322Z",
     "shell.execute_reply.started": "2024-06-13T23:07:50.015821Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate Mean Absolute Percentage Error (MAPE)\n",
    "mape = mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T22:39:16.463629Z",
     "iopub.status.busy": "2024-06-13T22:39:16.462843Z",
     "iopub.status.idle": "2024-06-13T22:46:12.493386Z",
     "shell.execute_reply": "2024-06-13T22:46:12.492015Z",
     "shell.execute_reply.started": "2024-06-13T22:39:16.463597Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    # Define the XGBoost model with the given parameters\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        max_depth=int(params['max_depth']),\n",
    "        learning_rate=params['learning_rate'],\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        gamma=params['gamma'],\n",
    "        reg_alpha=params['reg_alpha'],\n",
    "        reg_lambda=params['reg_lambda']\n",
    "    )\n",
    "\n",
    "    # Calculate the MAPE using cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_absolute_percentage_error')\n",
    "    # Negate the score as hyperopt minimizes the objective function\n",
    "    mape = -cv_scores.mean()\n",
    "\n",
    "    return mape\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 1000, 50),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -5, 0),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'gamma': hp.loguniform('gamma', -5, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, 0),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -5, 0)\n",
    "}\n",
    "\n",
    "# Create a trials object to store the results\n",
    "trials = Trials()\n",
    "\n",
    "# Run the optimization\n",
    "best_params = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,  # Number of trials\n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Train the XGBoost model with the best parameters\n",
    "best_model = xgb.XGBRegressor(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the MAPE on the test set\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(\"MAPE on test set:\", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T15:40:53.978947Z",
     "iopub.status.busy": "2024-06-13T15:40:53.978020Z",
     "iopub.status.idle": "2024-06-13T15:42:00.677393Z",
     "shell.execute_reply": "2024-06-13T15:42:00.676572Z",
     "shell.execute_reply.started": "2024-06-13T15:40:53.978914Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom MAPE Loss Function\n",
    "def mape_loss(y_true, y_pred):\n",
    "    epsilon = tf.keras.backend.epsilon()  \n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    diff = tf.abs((y_true - y_pred) / tf.keras.backend.maximum(tf.abs(y_true), epsilon))\n",
    "    return 100. * tf.keras.backend.mean(diff)\n",
    "\n",
    "# Advanced Dense Layer Modela\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(15,)),  # Assuming 15 features\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    layers.Dense(1, activation='linear') \n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(loss=mape_loss, optimizer='adam', metrics=['mean_absolute_percentage_error'])\n",
    "\n",
    "# Fit Model\n",
    "history = model.fit(X_train, y_train, epochs=200, validation_split=0.15)\n",
    "\n",
    "# Plot Training MAPE Loss\n",
    "plt.plot(history.history['mean_absolute_percentage_error'])\n",
    "plt.title('Training MAPE Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAPE (%)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T15:45:07.582473Z",
     "iopub.status.busy": "2024-06-13T15:45:07.581586Z",
     "iopub.status.idle": "2024-06-13T15:45:59.557354Z",
     "shell.execute_reply": "2024-06-13T15:45:59.556466Z",
     "shell.execute_reply.started": "2024-06-13T15:45:07.582444Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom MAPE Loss Function\n",
    "def mape_loss(y_true, y_pred):\n",
    "    epsilon = tf.keras.backend.epsilon()  \n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    diff = tf.abs((y_true - y_pred) / tf.keras.backend.maximum(tf.abs(y_true), epsilon))\n",
    "    return 100. * tf.keras.backend.mean(diff)\n",
    "\n",
    "# Advanced Dense Layer Model\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(15,)),  # Assuming 15 features\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    layers.Dense(1, activation='linear') \n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(loss=mape_loss, optimizer='adam', metrics=['mean_absolute_percentage_error'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, min_delta=0.001)\n",
    "\n",
    "# Define learning rate scheduler\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(lambda epoch: 0.001 * 0.9 ** (epoch // 10))\n",
    "\n",
    "# Fit Model\n",
    "history = model.fit(X_train, y_train, epochs=200, validation_split=0.15, \n",
    "                    callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "# Plot Training MAPE Loss\n",
    "plt.plot(history.history['mean_absolute_percentage_error'])\n",
    "plt.title('Training MAPE Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAPE (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:16:07.985295Z",
     "iopub.status.busy": "2024-06-13T23:16:07.984924Z",
     "iopub.status.idle": "2024-06-13T23:18:51.924826Z",
     "shell.execute_reply": "2024-06-13T23:18:51.923739Z",
     "shell.execute_reply.started": "2024-06-13T23:16:07.985266Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U pip\n",
    "!pip install -U setuptools wheel\n",
    "!pip install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:19:02.725813Z",
     "iopub.status.busy": "2024-06-13T23:19:02.725464Z",
     "iopub.status.idle": "2024-06-13T23:19:03.100913Z",
     "shell.execute_reply": "2024-06-13T23:19:03.099949Z",
     "shell.execute_reply.started": "2024-06-13T23:19:02.725784Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:19:03.103003Z",
     "iopub.status.busy": "2024-06-13T23:19:03.102588Z",
     "iopub.status.idle": "2024-06-13T23:19:03.177026Z",
     "shell.execute_reply": "2024-06-13T23:19:03.176084Z",
     "shell.execute_reply.started": "2024-06-13T23:19:03.102978Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv('/kaggle/input/rohlik-orders-forecasting-challenge/train.csv')\n",
    "df_ts = pd.read_csv('/kaggle/input/rohlik-orders-forecasting-challenge/test.csv')\n",
    "df_s = pd.read_csv('/kaggle/input/rohlik-orders-forecasting-challenge/solution_example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:19:03.780225Z",
     "iopub.status.busy": "2024-06-13T23:19:03.779364Z",
     "iopub.status.idle": "2024-06-13T23:19:03.806145Z",
     "shell.execute_reply": "2024-06-13T23:19:03.805040Z",
     "shell.execute_reply.started": "2024-06-13T23:19:03.780191Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['shutdown', 'mini_shutdown','blackout', 'mov_change', 'frankfurt_shutdown',\n",
    "       'precipitation', 'snow', 'user_activity_1', 'user_activity_2',]\n",
    "df_tr = df_tr.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:19:04.880641Z",
     "iopub.status.busy": "2024-06-13T23:19:04.879751Z",
     "iopub.status.idle": "2024-06-13T23:19:04.889248Z",
     "shell.execute_reply": "2024-06-13T23:19:04.888201Z",
     "shell.execute_reply.started": "2024-06-13T23:19:04.880603Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_tr['holiday_name'].fillna('noholiday', inplace=True)\n",
    "df_ts['holiday_name'].fillna('noholiday', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:19:06.530662Z",
     "iopub.status.busy": "2024-06-13T23:19:06.530002Z",
     "iopub.status.idle": "2024-06-13T23:19:06.537872Z",
     "shell.execute_reply": "2024-06-13T23:19:06.536816Z",
     "shell.execute_reply.started": "2024-06-13T23:19:06.530627Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_tr = df_tr.drop(['id'], axis=1)\n",
    "df_ts = df_ts.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:20:06.551202Z",
     "iopub.status.busy": "2024-06-13T23:20:06.550028Z",
     "iopub.status.idle": "2024-06-13T23:20:07.721825Z",
     "shell.execute_reply": "2024-06-13T23:20:07.720810Z",
     "shell.execute_reply.started": "2024-06-13T23:20:06.551151Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:23:32.520749Z",
     "iopub.status.busy": "2024-06-13T23:23:32.520073Z",
     "iopub.status.idle": "2024-06-14T00:23:46.503812Z",
     "shell.execute_reply": "2024-06-14T00:23:46.502544Z",
     "shell.execute_reply.started": "2024-06-13T23:23:32.520717Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predictor = TabularPredictor(label='orders',path=\"autogluon-daily\",eval_metric=\"mape\",).fit(df_tr, presets='best_quality', time_limit=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T00:25:11.530444Z",
     "iopub.status.busy": "2024-06-14T00:25:11.529499Z",
     "iopub.status.idle": "2024-06-14T00:25:11.567693Z",
     "shell.execute_reply": "2024-06-14T00:25:11.566635Z",
     "shell.execute_reply.started": "2024-06-14T00:25:11.530407Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T00:28:04.258983Z",
     "iopub.status.busy": "2024-06-14T00:28:04.258560Z",
     "iopub.status.idle": "2024-06-14T00:28:18.721457Z",
     "shell.execute_reply": "2024-06-14T00:28:18.720531Z",
     "shell.execute_reply.started": "2024-06-14T00:28:04.258939Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "preds=predictor.predict(df_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T00:49:14.915111Z",
     "iopub.status.busy": "2024-06-14T00:49:14.914110Z",
     "iopub.status.idle": "2024-06-14T00:49:22.946269Z",
     "shell.execute_reply": "2024-06-14T00:49:22.945259Z",
     "shell.execute_reply.started": "2024-06-14T00:49:14.915075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "preds=predictor.predict(df_ts, model='NeuralNetFastAI_BAG_L2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T00:49:22.948700Z",
     "iopub.status.busy": "2024-06-14T00:49:22.948351Z",
     "iopub.status.idle": "2024-06-14T00:49:22.956771Z",
     "shell.execute_reply": "2024-06-14T00:49:22.955761Z",
     "shell.execute_reply.started": "2024-06-14T00:49:22.948673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T00:49:22.959030Z",
     "iopub.status.busy": "2024-06-14T00:49:22.958368Z",
     "iopub.status.idle": "2024-06-14T00:49:22.972298Z",
     "shell.execute_reply": "2024-06-14T00:49:22.971444Z",
     "shell.execute_reply.started": "2024-06-14T00:49:22.959002Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_s = pd.read_csv('/kaggle/input/rohlik-orders-forecasting-challenge/solution_example.csv')\n",
    "df_s['orders']=preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T00:49:22.975016Z",
     "iopub.status.busy": "2024-06-14T00:49:22.974584Z",
     "iopub.status.idle": "2024-06-14T00:49:22.986739Z",
     "shell.execute_reply": "2024-06-14T00:49:22.985773Z",
     "shell.execute_reply.started": "2024-06-14T00:49:22.974980Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T00:49:22.988249Z",
     "iopub.status.busy": "2024-06-14T00:49:22.987853Z",
     "iopub.status.idle": "2024-06-14T00:49:22.998750Z",
     "shell.execute_reply": "2024-06-14T00:49:22.997907Z",
     "shell.execute_reply.started": "2024-06-14T00:49:22.988212Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_s = df_s.set_index('id')\n",
    "df_s.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
